#!/bin/ruby

############################################################################
#                      Â© 2023 Tony-Linux. All Rights Reserved.             #
#          For inquiries regarding this project, kindly reach out to:      #
#                    Email: mrhunter5@proton.me                            #
#                                                                          #
#    This content is protected by copyright law and may not be replicated  #
#     or altered without the explicit written consent of the copyright     #
#                               holder.                                    #
############################################################################

require 'uri'
require 'net/http'
require 'openssl'

def validate_and_sanitize_url(url)
  uri = URI.parse(url)
  return nil unless uri.scheme == 'http' || uri.scheme == 'https'

  uri.to_s
end

def scan_website(url)
  uri = URI.parse(url)
  response = Net::HTTP.get_response(uri)

  return [] unless response.is_a?(Net::HTTPSuccess)

  response.body.scan(/href="([^"#]*)"|\ssrc="([^"#]*)"/).flatten.compact
end

def display_files(files, type, base_url)
  return if files.empty?

  puts "\e[37m [\e[32m+\e[37m]\e[32m #{type} files :"
  files.each do |file|
    display_url = URI.join(base_url, file).to_s
    puts "\e[37m [\e[32m+\e[37m]\e[32m Link : #{display_url}"
  end
  puts
end

def scan_hidden_files(url)
  uri = URI.parse(url)
  http = Net::HTTP.new(uri.host, uri.port)
  http.use_ssl = (uri.scheme == 'https')
  http.verify_mode = OpenSSL::SSL::VERIFY_PEER

  request = Net::HTTP::Get.new(uri)
  request['User-Agent'] = 'Googlebot'
  response = http.request(request)

  hidden_files = []
  if response.is_a?(Net::HTTPSuccess)
    response.body.scan(/href="([^"#]*)"/).flatten.compact.each do |file|
      hidden_files << file if file.start_with?(".") || file.include?("/.")
    end
  end

  hidden_files
end

website_url = ARGV[0]

if website_url.nil?
  puts "Usage: secret-web <website_url>"
  exit 1
end

website_url = validate_and_sanitize_url(website_url)
if website_url.nil?
  puts "\e[37m [\e[31m+\e[37m]\e[31m Invalid URL format."
  exit 1
end

resources = scan_website(website_url)

pdf_files = resources.grep(/\.pdf$/i)
image_files = resources.grep(/\.(jpg|jpeg|png)$/i)
video_files = resources.grep(/\.(mp4|avi)$/i)
php_files = resources.grep(/\.php$/i)
zip_files = resources.grep(/\.zip$/i)
doc_files = resources.grep(/\.(doc|docx|txt)$/i)

display_files(image_files, "Image", website_url) if !image_files.empty?
display_files(pdf_files, "PDF", website_url) if !pdf_files.empty?
display_files(video_files, "Video", website_url) if !video_files.empty?
display_files(php_files, "PHP", website_url) if !php_files.empty?
display_files(zip_files, "ZIP", website_url) if !zip_files.empty?
display_files(doc_files, "Document", website_url) if !doc_files.empty?

hidden_files = scan_hidden_files(website_url)
if !hidden_files.empty?
  display_files(hidden_files, "Hidden", website_url)
else
  puts "\e[37m [\e[31m+\e[37m]\e[31m No hidden files available."
end
